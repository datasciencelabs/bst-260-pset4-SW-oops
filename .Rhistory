regions <- regions |>
unnest()
dim(regions)
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest()
view(regions)
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest() |>
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name
)
)
view(regions)
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
class(regions)
regions <- regions |>
unnest() |>  #unnest the lists within the dataframe
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name
)
)
view(regions)
population$state_name <- as.character(population$state_name)  # convert to character from list, previously the right join returned an error
population <- right_join(regions, population, by = "state_name")
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest() |>  #unnest the lists within the dataframe
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name  #avoid non-matching values become NA
)
)
# view(regions)
source("census-key.R")
url <- "https://api.census.gov/data/2021/pep/population"
#| message: false
#| warning: false
library(httr2)
request <- request(url) |>
req_url_query(
get = "POP_2020,POP_2021,NAME",
"for" = "state:*",
key = census_key
)
request
response <- req_perform(request)
response
resp_content_type(response)
population <- resp_body_json(response)
population <- do.call(rbind, population) #convert to matrix
# view(population)
#| message: false
#| warning: false
library(tidyverse)
library(janitor)
population <- population |>
as_tibble() |>   # convert to tibble
janitor::row_to_names(row_number = 1) |>## Use janitor row to names function |>
select(-state) |>   # remove stat column
rename(state_name = NAME)  |> # rename state column to state_name
pivot_longer(cols = c(POP_2020, POP_2021),
names_to = "year",
values_to = "pop",
names_prefix = "POP_") |> # use pivot_longer to tidy # remove POP_ from year
mutate(across(c(year, pop), as.numeric)) |> # parese all relevant columns to numeric
mutate(state = state.abb[match(state_name, state.name)]) |> # add state abbreviations using state.abb variable
mutate(
state = case_when(
state_name == "District of Columbia" ~ "DC",
state_name == "Puerto Rico" ~ "PR",
.default = state
)
)# use case_when to add abbreviations for DC and PR
# view(population)
population |>
mutate(state = reorder(state, pop, mean)) |> # reorder state # by both year
ggplot(aes(x = state, y = pop/1000)) + # assign aesthetic mapping
geom_col() + # use geom_col to plot barplot
coord_flip() + # flip coordinates
facet_wrap(~ year) + # facet by year
labs(y = "population, 1000",  # divide by 1000 for clarity
title = "State population by year") +
theme_bw()
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest() |>  #unnest the lists within the dataframe
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name  #avoid non-matching values become NA
)
)
# view(regions)
population$state_name <- as.character(population$state_name)  # convert to character from list, previously the right join returned an error
population <- right_join(regions, population, by = "state_name")
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest() |>  #unnest the lists within the dataframe
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name  #avoid non-matching values become NA
)
) |>
rename(state_name = states)
# view(regions)
population$state_name <- as.character(population$state_name)  # convert to character from list, previously the right join returned an error
population <- right_join(regions, population, by = "state_name")
view(population)
api <- "https://data.cdc.gov/resource/pwn4-m3yp.json"
cases_raw <- request(api)|>
req_url_query(`$limit` = 10000000000) |>
req_perform() |>
resp_body_string() |>
fromJSON()
# str(cases_raw)  #10380 obs. of  10 variables:
# head(cases_raw)
cases <- cases_raw |>
as_tibble() |>
select(state, end_date, new_cases) |>
rename(date = end_date, cases = new_cases) |>
mutate(across(c(cases), parse_number)) |>
mutate(across(c(date), as.Date))  # seconds were all 00, drop the information
# head(cases)
library(lubridate)
library(knitr)
#| message: false
#| warning: false
#in Q11, dates were already in date format, not a string
#covert it back to string to satisfy the requirement
cases |>
mutate(
date = as.character(date)  # back to character
) |>
mutate(
year = year(date),
month = month(date, label = TRUE)
) |>
left_join(population, by = c("state", "year")) |># merge with population dataset by abbreviation
select(state, cases, year, month) |>
filter(year == 2020 | year == 2021) |>
group_by(month, year) |>
summarise(
totalcases = sum(cases),
.groups = "drop"
) |>
arrange(year, month) |>
kable()
library(lubridate)
library(knitr)
#| message: false
#| warning: false
#in Q11, dates were already in date format, not a string
cases |>
mutate(
year = year(date),
month = month(date, label = TRUE)
) |>
left_join(population, by = c("state", "year")) |># merge with population dataset by abbreviation
select(state, cases, year, month) |>
filter(year == 2020 | year == 2021) |>
group_by(month, year) |>
summarise(
totalcases = sum(cases),
.groups = "drop"
) |>
arrange(year, month) |>
kable()
deaths_raw <- request(deaths_url)|>
req_url_query(`$limit` = 10000000000) |>
req_perform() |>
resp_body_string() |>
fromJSON()
source("census-key.R")
url <- "https://api.census.gov/data/2021/pep/population"
#| message: false
#| warning: false
library(httr2)
request <- request(url) |>
req_url_query(
get = "POP_2020,POP_2021,NAME",
"for" = "state:*",
key = census_key
)
# request
response <- req_perform(request)
# response
resp_status(response)
resp_content_type(response)
population <- resp_body_json(response)
population <- do.call(rbind, population) #convert to matrix
# view(population)
#| message: false
#| warning: false
library(tidyverse)
library(janitor)
population <- population |>
as_tibble() |>   # convert to tibble
janitor::row_to_names(row_number = 1) |>## Use janitor row to names function |>
select(-state) |>   # remove stat column
rename(state_name = NAME)  |> # rename state column to state_name
pivot_longer(cols = c(POP_2020, POP_2021),
names_to = "year",
values_to = "pop",
names_prefix = "POP_") |> # use pivot_longer to tidy # remove POP_ from year
mutate(across(c(year, pop), as.numeric)) |> # parese all relevant columns to numeric
mutate(state = state.abb[match(state_name, state.name)]) |> # add state abbreviations using state.abb variable
mutate(
state = case_when(
state_name == "District of Columbia" ~ "DC",
state_name == "Puerto Rico" ~ "PR",
.default = state
)
)# use case_when to add abbreviations for DC and PR
# view(population)
population |>
mutate(state = reorder(state, pop, mean)) |> # reorder state # by both year
ggplot(aes(x = state, y = pop/1000)) + # assign aesthetic mapping
geom_col() + # use geom_col to plot barplot
coord_flip() + # flip coordinates
facet_wrap(~ year) + # facet by year
labs(y = "population, 1000",  # divide by 1000 for clarity
title = "State population by year") +
theme_bw()
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest() |>  #unnest the lists within the dataframe
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name  #avoid non-matching values become NA
)
) |>
rename(state_name = states)
view(regions)
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest() |>  #unnest the lists within the dataframe
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name  #avoid non-matching values become NA
)
) |>
rename(state_name = states) |>
filter(state_name %in% c(state.abb))
# view(regions) #have 59 rows, filter out to match Census (added to the last step above)
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest() |>  #unnest the lists within the dataframe
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name  #avoid non-matching values become NA
)
) |>
rename(state_name = states) |>
filter(state_name %in% c(state.abb))
view(regions) #have 59 rows, filter out to match Census (added to the last step above)
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest() |>  #unnest the lists within the dataframe
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name  #avoid non-matching values become NA
)
) |>
rename(state_name = states) |>
filter(state_name %in% c(state.name))
source("census-key.R")
url <- "https://api.census.gov/data/2021/pep/population"
#| message: false
#| warning: false
library(httr2)
request <- request(url) |>
req_url_query(
get = "POP_2020,POP_2021,NAME",
"for" = "state:*",
key = census_key
)
# request
response <- req_perform(request)
# response
resp_status(response)
resp_content_type(response)
population <- resp_body_json(response)
population <- do.call(rbind, population) #convert to matrix
# view(population)
#| message: false
#| warning: false
library(tidyverse)
library(janitor)
population <- population |>
as_tibble() |>   # convert to tibble
janitor::row_to_names(row_number = 1) |>## Use janitor row to names function |>
select(-state) |>   # remove stat column
rename(state_name = NAME)  |> # rename state column to state_name
pivot_longer(cols = c(POP_2020, POP_2021),
names_to = "year",
values_to = "pop",
names_prefix = "POP_") |> # use pivot_longer to tidy # remove POP_ from year
mutate(across(c(year, pop), as.numeric)) |> # parese all relevant columns to numeric
mutate(state = state.abb[match(state_name, state.name)]) |> # add state abbreviations using state.abb variable
mutate(
state = case_when(
state_name == "District of Columbia" ~ "DC",
state_name == "Puerto Rico" ~ "PR",
.default = state
)
)# use case_when to add abbreviations for DC and PR
# view(population)
population |>
mutate(state = reorder(state, pop, mean)) |> # reorder state # by both year
ggplot(aes(x = state, y = pop/1000)) + # assign aesthetic mapping
geom_col() + # use geom_col to plot barplot
coord_flip() + # flip coordinates
facet_wrap(~ year) + # facet by year
labs(y = "population, 1000",  # divide by 1000 for clarity
title = "State population by year") +
theme_bw()
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest() |>  #unnest the lists within the dataframe
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name  #avoid non-matching values become NA
)
) |>
rename(state_name = states) |>
filter(state_name %in% c(state.name))
view(regions) #have 59 rows, filter out to match Census (added to the last step above)
source("census-key.R")
url <- "https://api.census.gov/data/2021/pep/population"
#| message: false
#| warning: false
library(httr2)
request <- request(url) |>
req_url_query(
get = "POP_2020,POP_2021,NAME",
"for" = "state:*",
key = census_key
)
# request
response <- req_perform(request)
# response
resp_status(response)
resp_content_type(response)
population <- resp_body_json(response)
population <- do.call(rbind, population) #convert to matrix
# view(population)
#| message: false
#| warning: false
library(tidyverse)
library(janitor)
population <- population |>
as_tibble() |>   # convert to tibble
janitor::row_to_names(row_number = 1) |>## Use janitor row to names function |>
select(-state) |>   # remove stat column
rename(state_name = NAME)  |> # rename state column to state_name
pivot_longer(cols = c(POP_2020, POP_2021),
names_to = "year",
values_to = "pop",
names_prefix = "POP_") |> # use pivot_longer to tidy # remove POP_ from year
mutate(across(c(year, pop), as.numeric)) |> # parese all relevant columns to numeric
mutate(state = state.abb[match(state_name, state.name)]) |> # add state abbreviations using state.abb variable
mutate(
state = case_when(
state_name == "District of Columbia" ~ "DC",
state_name == "Puerto Rico" ~ "PR",
.default = state
)
)# use case_when to add abbreviations for DC and PR
# view(population)
population |>
mutate(state = reorder(state, pop, mean)) |> # reorder state # by both year
ggplot(aes(x = state, y = pop/1000)) + # assign aesthetic mapping
geom_col() + # use geom_col to plot barplot
coord_flip() + # flip coordinates
facet_wrap(~ year) + # facet by year
labs(y = "population, 1000",  # divide by 1000 for clarity
title = "State population by year") +
theme_bw()
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
#| message: false
#| warning: false
library(jsonlite)
library(purrr)
url <- "https://github.com/datasciencelabs/2025/raw/refs/heads/main/data/regions.json"
regions <- fromJSON(url, flatten = TRUE) # use jsonlit JSON parser
regions <- regions |>
unnest() |>  #unnest the lists within the dataframe
mutate(
region_name = case_when(
region_name == "New York and New Jersey, Puerto Rico, Virgin Islands" ~ "NY, NJ, PR, VI",
.default = region_name  #avoid non-matching values become NA
)
) |>
rename(state_name = states) |>
filter(state_name %in% c(state.name, "District of Columbia", "Puerto Rico"))
view(regions) #have 59 rows, filter out to match Census (added to the last step above)
population$state_name <- as.character(population$state_name)  # convert to character from list, previously the right join returned an error
population <- right_join(regions, population, by = "state_name")
view(population)
api <- "https://data.cdc.gov/resource/pwn4-m3yp.json"
cases_raw <- request(api)|>
req_perform() |>
resp_body_string() |>
fromJSON()
# str(cases_raw)
# 1000 obs. of  10 variables
# There is only 1000 obs because API often limit how much you can download. We can use the req_url_query to add a limit to the syntax
api <- "https://data.cdc.gov/resource/pwn4-m3yp.json"
cases_raw <- request(api)|>
req_url_query(`$limit` = 10000000000) |>
req_perform() |>
resp_body_string() |>
fromJSON()
# str(cases_raw)  #10380 obs. of  10 variables:
# head(cases_raw)
cases <- cases_raw |>
as_tibble() |>
select(state, end_date, new_cases) |>
rename(date = end_date, cases = new_cases) |>
mutate(across(c(cases), parse_number)) |>
mutate(across(c(date), as.Date))  # seconds were all 00, drop the information
# head(cases)
cases |>
mutate(year = year(date)) |>
inner_join(population, by = c("state", "year")) |># merge with population dataset by abbreviation
select(state, date, cases, region_name, pop, year) |>
filter(date >= "2020-01-01" & date < "2022-01-01") |>
ggplot(aes(x = date, y = cases/pop*100000, group = state, color = state)) +
#  geom_point() +
geom_line() +
facet_wrap(~ region_name) +
scale_x_date(
date_breaks = "1 year",      # tick every 1 year
date_labels = "%Y"           # show just the year
) +
labs(
title = "New cases per 100,000 by time, 2020-2021",
y = "Cases per 100,000",
x = "Year"
) +
theme_classic()
